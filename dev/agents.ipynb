{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jordan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain-community in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (0.0.29)\n",
      "Requirement already satisfied: langchain in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (0.1.13)\n",
      "Collecting crewai\n",
      "  Downloading crewai-0.22.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain-openai in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (0.1.0)\n",
      "Collecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-5.1.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain-community) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain-community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain-community) (0.6.4)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain-community) (0.1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain-community) (0.1.31)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain) (2.6.4)\n",
      "Collecting click<9.0.0,>=8.1.7 (from crewai)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting instructor<0.6.0,>=0.5.2 (from crewai)\n",
      "  Downloading instructor-0.5.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.0.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.13.3 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from crewai) (1.14.2)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-dotenv==1.0.0 (from crewai)\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: regex<2024.0.0,>=2023.12.25 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from crewai) (2023.12.25)\n",
      "Collecting tiktoken<0.6.0,>=0.5.2 (from langchain-openai)\n",
      "  Downloading tiktoken-0.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting curl-cffi>=0.6.2 (from duckduckgo-search)\n",
      "  Downloading curl_cffi-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting lxml>=5.1.0 (from duckduckgo-search)\n",
      "  Downloading lxml-5.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Collecting cffi>=1.12.0 (from curl-cffi>=0.6.2->duckduckgo-search)\n",
      "  Downloading cffi-1.16.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from curl-cffi>=0.6.2->duckduckgo-search) (2024.2.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Collecting docstring-parser<0.16,>=0.15 (from instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from instructor<0.6.0,>=0.5.2->crewai) (13.7.1)\n",
      "Collecting typer<0.10.0,>=0.9.0 (from instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (4.3.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.9.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.13.3->crewai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.13.3->crewai) (0.25.2)\n",
      "Requirement already satisfied: sniffio in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.13.3->crewai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.13.3->crewai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.13.3->crewai) (4.10.0)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.19 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from opentelemetry-proto==1.23.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (4.25.3)\n",
      "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Collecting pycparser (from cffi>=1.12.0->curl-cffi>=0.6.2->duckduckgo-search)\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai) (1.16.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (0.14.0)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai) (2.17.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jordan/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai) (0.1.2)\n",
      "Downloading crewai-0.22.5-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
      "Downloading duckduckgo_search-5.1.0-py3-none-any.whl (21 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading curl_cffi-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading instructor-0.5.2-py3-none-any.whl (33 kB)\n",
      "Downloading lxml-5.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m453.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.23.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m428.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m143.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
      "Downloading tiktoken-0.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cffi-1.16.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (477 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m477.6/477.6 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m351.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m661.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zipp, python-dotenv, pycparser, opentelemetry-semantic-conventions, opentelemetry-proto, lxml, googleapis-common-protos, docstring-parser, deprecated, click, typer, tiktoken, opentelemetry-exporter-otlp-proto-common, importlib-metadata, cffi, opentelemetry-api, curl-cffi, opentelemetry-sdk, instructor, duckduckgo-search, opentelemetry-exporter-otlp-proto-http, langchain-openai, crewai\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.6.0\n",
      "    Uninstalling tiktoken-0.6.0:\n",
      "      Successfully uninstalled tiktoken-0.6.0\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 0.1.0\n",
      "    Uninstalling langchain-openai-0.1.0:\n",
      "      Successfully uninstalled langchain-openai-0.1.0\n",
      "Successfully installed cffi-1.16.0 click-8.1.7 crewai-0.22.5 curl-cffi-0.6.2 deprecated-1.2.14 docstring-parser-0.15 duckduckgo-search-5.1.0 googleapis-common-protos-1.63.0 importlib-metadata-6.11.0 instructor-0.5.2 langchain-openai-0.0.5 lxml-5.1.0 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-http-1.23.0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 pycparser-2.21 python-dotenv-1.0.0 tiktoken-0.5.2 typer-0.9.0 zipp-3.18.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community langchain crewai langchain-openai duckduckgo-search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'skC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Task\nexpected_output\n  Field required [type=missing, input_value={'description': 'Identify...everything about tech.)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 49\u001b[0m\n\u001b[1;32m     40\u001b[0m formater \u001b[38;5;241m=\u001b[39m Agent(\n\u001b[1;32m     41\u001b[0m   role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarkdown Formater\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     42\u001b[0m   goal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormat the text in markdown\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m   allow_delegation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Tasks\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m research_task \u001b[38;5;241m=\u001b[39m \u001b[43mTask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIdentify the next big trend in AI by searching internet once\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m  \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresearcher\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m insight_task \u001b[38;5;241m=\u001b[39m Task(\n\u001b[1;32m     55\u001b[0m   description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFind key insights from the data. Dont use any tool\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     56\u001b[0m   agent\u001b[38;5;241m=\u001b[39minsight_researcher\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     59\u001b[0m write_task \u001b[38;5;241m=\u001b[39m Task(\n\u001b[1;32m     60\u001b[0m   description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWrite a blog post. Dont use any tool\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     61\u001b[0m   agent\u001b[38;5;241m=\u001b[39mwriter\n\u001b[1;32m     62\u001b[0m )\n",
      "File \u001b[0;32m~/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages/crewai/task.py:76\u001b[0m, in \u001b[0;36mTask.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(__pydantic_self__, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata):\n\u001b[1;32m     75\u001b[0m     config \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/LLM/HackTheRobots/.venv/lib/python3.12/site-packages/pydantic/main.py:171\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    170\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Task\nexpected_output\n  Field required [type=missing, input_value={'description': 'Identify...everything about tech.)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# Set the OpenAI API key and model name\n",
    "OPENAI_API_KEY = 'sk-1234567890' \n",
    "OPENAI_MODEL_NAME='openhermes'  # Adjust based on available model\n",
    "OPENAI_API_BASE='http://localhost:11434/v1'\n",
    "OPENAI_MODEL_NAME='openhermes'  # Adjust based on available model\n",
    "\n",
    "# Create a researcher agent\n",
    "researcher = Agent(\n",
    "  role='Senior Researcher',\n",
    "  goal='Discover groundbreaking technologies',\n",
    "  backstory='A curious mind fascinated by cutting-edge innovation and the potential to change the world, you know everything about tech.',\n",
    "  verbose=True,\n",
    "  tools=[search_tool],\n",
    "  allow_delegation=False,\n",
    ")\n",
    "\n",
    "insight_researcher = Agent(\n",
    "  role='Insight Researcher',\n",
    "  goal='Discover Key Insights',\n",
    "  backstory='You are able to find key insights from the data you are given.',\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "  role='Tech Content Strategist',\n",
    "  goal='Craft compelling content on tech advancements',\n",
    "  backstory=\"\"\"You are a content strategist known for \n",
    "  making complex tech topics interesting and easy to understand.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    ")\n",
    "\n",
    "formater = Agent(\n",
    "  role='Markdown Formater',\n",
    "  goal='Format the text in markdown',\n",
    "  backstory='You are able to convert the text into markdown format',\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    ")\n",
    "\n",
    "# Tasks\n",
    "research_task = Task(\n",
    "  description='Identify the next big trend in AI by searching internet once',\n",
    "  agent=researcher\n",
    ")\n",
    "\n",
    "insight_task = Task(\n",
    "  description='Find key insights from the data. Dont use any tool',\n",
    "  agent=insight_researcher\n",
    ")\n",
    "\n",
    "write_task = Task(\n",
    "  description='Write a blog post. Dont use any tool',\n",
    "  agent=writer\n",
    ")\n",
    "\n",
    "format_task = Task(\n",
    "  description='convert the input to markdown format',\n",
    "  agent=formater\n",
    ")\n",
    "\n",
    "# Instantiate a crew\n",
    "tech_crew = Crew(\n",
    "  agents=[researcher, insight_researcher, writer, formater],\n",
    "  tasks=[research_task, insight_task, write_task, format_task],\n",
    "  process=Process.sequential  # Tasks will be executed one after the other\n",
    ")\n",
    "\n",
    "# Begin the task execution\n",
    "result = tech_crew.kickoff()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm_ollama = Ollama(model=\"orca2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
